---
sidebar: sidebar 
permalink: xcp/xcp-bp-deployment-steps.html 
keywords: deployment, solution components, linux server, windows server aff a800, ha 
summary: Dieser Abschnitt behandelt die Bereitstellungsschritte für NetApp XCP zur Datenübertragung. 
---
= Bereitstellungsschritte
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Dieser Abschnitt behandelt die Bereitstellungsschritte für NetApp XCP zur Datenübertragung.



== Prüfstandsdetails

Die folgende Tabelle enthält die Details des Testbetts, das für diese Bereitstellung und Leistungsvalidierung verwendet wurde.

|===
| Lösungskomponenten | Details 


| XCP-Version 1.7  a| 
* Ein Linux-Server – Linux (RHEL 7.9 oder RHEL 8)
* Ein Windows-Server – Windows Server 2019 Standard




| NetApp AFF Speicherarray-HA-Paar für das Quellvolume  a| 
* AFF8080
* NetApp ONTAP 9
* NFS-Protokoll




| NetApp AFF Speicherarray-HA-Paar für Zielvolume  a| 
* AFF A800
* ONTAP 9
* NFS-Protokoll




| Fujitsu PRIMERGY RX2540 Server | Jeder ist ausgestattet mit: * 48 CPUs * Intel Xeon * 256 GB physischem Speicher * 10 GbE Dual-Port 


| Vernetzung | 10GbE 
|===


== Bereitstellungsschritte – NAS

Um NetApp XCP für die Datenübertragung bereitzustellen, installieren und aktivieren Sie zunächst die XCP-Software am Zielspeicherort.  Sie können die Details im https://mysupport.netapp.com/documentation/productlibrary/index.html?productID=63064["NetApp XCP-Benutzerhandbuch"^] .  Führen Sie dazu die folgenden Schritte aus:

. Erfüllen Sie die Voraussetzungen wie im Abschnitt beschriebenlink:xcp-bp-netapp-xcp-overview.html#prerequisites-for-xcp["Voraussetzungen für XCP."]
. Laden Sie die XCP-Software von der https://mysupport.netapp.com/site/products/all/details/netapp-xcp/downloads-tab["NetApp XCP (Downloads)-Seite"^] .
. Kopieren Sie die heruntergeladenen XCP-Tar-Dateien auf den XCP-Server.
+
....
# scp Documents/OneDrive\ -\ NetApp\ Inc/XCP/software/1.6.1/NETAPP_XCP_1.6.1.tgz mailto:root@10.63.150.53:/usr/src
....
. Entpacken Sie die Tar-Datei.
+
....
[root@mastr-53 src]# tar -zxvf NETAPP_XCP_1.6.1.tgz
....
. Laden Sie die Lizenz herunter von https://xcp.netapp.com/license/xcp.xwic%20["https://xcp.netapp.com/license/xcp.xwic"^] und auf den XCP-Server kopieren.
. Aktivieren Sie die Lizenz.
+
....
[root@mastr-53 linux]# ./xcp activate
[root@mastr-53 src]# cp license /opt/NetApp/xFiles/xcp/license
[root@mastr-53 src]# cd /usr/src/xcp/linux/
[root@mastr-53 linux]# ./xcp activate
....
. Suchen Sie den Quell-NFS-Port und den Ziel-NFS-Server.  Der Standardport ist 2049.
+
....
[root@mastr-53 ~]# rpcinfo -p 10.63.150.213
[root@mastr-53 ~]# rpcinfo -p 10.63.150.63
....
. Überprüfen Sie die NFS-Verbindung.  Überprüfen Sie den NFS-Server (sowohl für Quelle als auch für Ziel), indem Sie per Telnet auf den NFS-Server-Port zugreifen.
+
....
[root@mastr-53 ~]# telnet 10.63.150.127 2049
[root@mastr-53 ~]# telnet 10.63.150.63 2049
....
. Konfigurieren Sie den Katalog.
+
.. Erstellen Sie ein NFS-Volume und exportieren Sie NFS für den XCP-Katalog.  Sie können auch den NFS-Export des Betriebssystems für den XCP-Katalog nutzen.
+
....
A800-Node1-2::> volume create -vserver Hadoop_SVM -volume xcpcatalog -aggregate aggr_Hadoop_1 -size 50GB -state online -junction-path /xcpcatalog -policy default -unix-permissions ---rwxr-xr-x -type RW -snapshot-policy default -foreground true
A800-Node1-2::> volume mount -vserver Hadoop_SVM -volume xcpcatalog_vol -junction-path /xcpcatalog
....
.. Überprüfen Sie den NFS-Export.
+
....
[root@mastr-53 ~]# showmount -e 10.63.150.63 | grep xcpca
/xcpcatalog (everyone)
....
.. Aktualisieren `xcp.ini` .
+
....
[root@mastr-53 ~]# cat /opt/NetApp/xFiles/xcp/xcp.ini
# Sample xcp config
[xcp]
catalog = 10.63.150.64:/xcpcatalog

[root@mastr-53 ~]#
....


. Suchen Sie die Quell-NAS-Exporte mithilfe von `xcp show` .  Suchen:
+
....
== NFS Exports ==
== Attributes of NFS Exports ==
....
+
....
[root@mastr-53 linux]# ./xcp show 10.63.150.127
== NFS Exports ==
<check here>
== Attributes of NFS Exports ==
<check here>
....
. (Optional) Scannen Sie die Quell-NAS-Daten.
+
....
[root@mastr-53 linux]# ./xcp scan -newid xcpscantest4 -stats 10.63.150.127:/xcpsrc_vol
....
+
Durch das Scannen der NAS-Quelldaten können Sie das Datenlayout verstehen und mögliche Probleme bei der Migration erkennen.  Die Dauer des XCP-Scanvorgangs ist proportional zur Anzahl der Dateien und der Verzeichnistiefe.  Sie können diesen Schritt überspringen, wenn Sie mit Ihren NAS-Daten vertraut sind.

. Überprüfen Sie den Bericht, der erstellt wurde von `xcp scan` .  Suchen Sie hauptsächlich nach nicht lesbaren Ordnern und nicht lesbaren Dateien.
+
....
[root@mastr-53 linux]# mount 10.63.150.64:/xcpcatalog  /xcpcatalog
base) nkarthik-mac-0:~ karthikeyannagalingam$ scp -r root@10.63.150.53:/xcpcatalog/catalog/indexes/xcpscantest4 Documents/OneDrive\ -\ NetApp\ Inc/XCP/customers/reports/
....
. (Optional) Ändern Sie den Inode.  Zeigen Sie die Anzahl der Inodes an und ändern Sie die Anzahl basierend auf der Anzahl der zu migrierenden oder zu kopierenden Dateien für Katalog- und Zielvolumes (falls erforderlich).
+
....
A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
A800-Node1-2::> volume modify -volume xcpcatalog -vserver A800-Node1_vs1 -files 2000000
Volume modify successful on volume xcpcatalog of Vserver A800-Node1_vs1.

A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
....
. Scannen Sie das Zielvolume.
+
....
[root@mastr-53 linux]# ./xcp scan -stats 10.63.150.63:/xcpdest
....
. Überprüfen Sie den Speicherplatz des Quell- und Zielvolumes.
+
....
[root@mastr-53 ~]# df -h /xcpsrc_vol
[root@mastr-53 ~]# df -h /xcpdest/
....
. Kopieren Sie die Daten von der Quelle zum Ziel, indem Sie `xcp copy` und überprüfen Sie die Zusammenfassung.
+
....
[root@mastr-53 linux]# ./xcp copy -newid create_Sep091599198212 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
<command inprogress results removed>
Xcp command : xcp copy -newid create_Sep091599198212 -parallel 23 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M copied, 118 linked, 9.07M indexed, 173 giants
Speed       : 1.57 TiB in (412 MiB/s), 1.50 TiB out (392 MiB/s)
Total Time  : 1h6m.
STATUS      : PASSED
[root@mastr-53 linux]#
....
+

NOTE: Standardmäßig erstellt XCP sieben parallele Prozesse zum Kopieren der Daten.  Dies kann angepasst werden.

+

NOTE: NetApp empfiehlt, das Quellvolume nur lesbar zu machen.  In Echtzeit ist das Quellvolume ein aktives Live-Dateisystem.  Der `xcp copy` Der Vorgang kann fehlschlagen, da NetApp XCP keine Live-Quelle unterstützt, die ständig von einer Anwendung geändert wird.

+
Für Linux erfordert XCP eine Index-ID, da XCP Linux die Katalogisierung durchführt.

. (Optional) Überprüfen Sie die Inodes auf dem NetApp Zielvolume.
+
....
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
vserver        volume  files    files-used
-------------- ------- -------- ----------
A800-Node1_vs1 xcpdest 21251126 15039685

A800-Node1-2::>
....
. Führen Sie das inkrementelle Update durch, indem Sie `xcp sync` .
+
....
[root@mastr-53 linux]# ./xcp sync -id create_Sep091599198212
Xcp command : xcp sync -id create_Sep091599198212
Stats       : 9.07M reviewed, 9.07M checked at source, no changes, 9.07M reindexed
Speed       : 1.73 GiB in (8.40 MiB/s), 1.98 GiB out (9.59 MiB/s)
Total Time  : 3m31s.
STATUS      : PASSED
....
+
Für dieses Dokument wurden zur Simulation von Echtzeit die eine Million Dateien in den Quelldaten umbenannt und anschließend die aktualisierten Dateien mithilfe von `xcp sync` .  Für Windows benötigt XCP sowohl Quell- als auch Zielpfade.

. Datenübertragung validieren.  Sie können überprüfen, ob Quelle und Ziel die gleichen Daten haben, indem Sie `xcp verify` .
+
....
Xcp command : xcp verify 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M indexed, 173 giants, 100% found (6.01M have data), 6.01M compared, 100% verified (data, attrs, mods)
Speed       : 3.13 TiB in (509 MiB/s), 11.1 GiB out (1.76 MiB/s)
Total Time  : 1h47m.
STATUS      : PASSED
....


Die XCP-Dokumentation bietet mehrere Optionen (mit Beispielen) für die `scan` , `copy` , `sync` , Und `verify` Operationen.  Weitere Informationen finden Sie im https://mysupport.netapp.com/documentation/productlibrary/index.html?productID=63064["NetApp XCP-Benutzerhandbuch"^] .


NOTE: Windows-Kunden sollten die Daten mithilfe von Zugriffskontrolllisten (ACLs) kopieren.  NetApp empfiehlt die Verwendung des Befehls `xcp copy -acl -fallbackuser\<username> -fallbackgroup\<username or groupname> <source> <destination>` .  Um eine maximale Leistung zu erzielen, muss das Ziel ein NTFS-Volume sein, wenn man das Quellvolume berücksichtigt, das SMB-Daten mit ACL enthält, und die Daten, auf die sowohl über NFS als auch über SMB zugegriffen werden kann.  Kopieren Sie mit XCP (NFS-Version) die Daten vom Linux-Server und führen Sie die XCP-Synchronisierung (SMB-Version) mit dem `-acl` Und `-nodata` Optionen vom Windows-Server, um die ACLs von den Quelldaten in die Ziel-SMB-Daten zu kopieren.

Ausführliche Schritte finden Sie unter https://helpcenter.netwrix.com/NA/Configure_IT_Infrastructure/Accounts/DCA_Manage_Auditing_Security_Log.html["Konfigurieren der Richtlinie „Überwachung und Sicherheitsprotokoll verwalten“"^] .



== Bereitstellungsschritte – HDFS/MapRFS-Datenmigration

In diesem Abschnitt besprechen wir die neue XCP-Funktion namens „Hadoop Filesystem Data Transfer to NAS“, die Daten von HDFS/MapRFS zu NFS und umgekehrt migriert.



=== Voraussetzungen

Für die MapRFS/HDFS-Funktion müssen Sie das folgende Verfahren in einer Umgebung ohne Root-Benutzer durchführen.  Normalerweise ist der Nicht-Root-Benutzer hdfs, mapr oder ein Benutzer, der die Berechtigung hat, Änderungen im HDFS- und MapRFS-Dateisystem vorzunehmen.

. Legen Sie die Variablen CLASSPATH, HADOOP_HOME, NHDFS_LIBJVM_PATH, LB_LIBRARY_PATH und NHDFS_LIBHDFS_PATH in der CLI oder der .bashrc-Datei des Benutzers zusammen mit dem `xcp` Befehl.
+
** NHDFS_LIBHDFS_PATH verweist auf die Datei libhdfs.so.  Diese Datei bietet HDFS-APIs zur Interaktion und Bearbeitung der HDFS/MapRFS-Dateien und des Dateisystems als Teil der Hadoop-Distribution.
** NHDFS_LIBJVM_PATH verweist auf die Datei libjvm.so.  Dies ist eine gemeinsam genutzte JAVA-Bibliothek für virtuelle Maschinen am JRE-Speicherort.
** CLASSPATH verweist auf alle JAR-Dateien mit Werten (Hadoop-Klassenpfad –glob).
** LD_LIBRARY_PATH verweist auf den Speicherort des nativen Hadoop-Bibliotheksordners.
+
Sehen Sie sich das folgende Beispiel basierend auf einem Cloudera-Cluster an.

+
[listing]
----
export CLASSPATH=$(hadoop classpath --glob)
export LD_LIBRARY_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/
export HADOOP_HOME=/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6751098/
#export HADOOP_HOME=/opt/cloudera/parcels/CDH/
export NHDFS_LIBJVM_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/libjvm.so
export NHDFS_LIBHDFS_PATH=$HADOOP_HOME/lib64/libhdfs.so
----
+
In dieser Version unterstützen wir XCP-Scan-, Kopier- und Überprüfungsvorgänge sowie die Datenmigration von HDFS zu NFS.  Sie können Daten von einem einzelnen Worker-Knoten und mehreren Worker-Knoten eines Data Lake-Clusters übertragen.  In der Version 1.8 können Root- und Nicht-Root-Benutzer eine Datenmigration durchführen.







=== Bereitstellungsschritte – Nicht-Root-Benutzer migriert HDFS/MaprFS-Daten zu NetApp NFS

. Befolgen Sie die gleichen Schritte 1–9 im Abschnitt „Schritte zur Bereitstellung“.
. Im folgenden Beispiel migriert der Benutzer Daten von HDFS zu NFS.
+
.. Erstellen Sie einen Ordner und Dateien (mit `hadoop fs -copyFromLocal` ) in HDFS.
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -mkdir /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]# su - tester -c 'hadoop fs -ls -d  /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
drwxr-xr-x   - tester supergroup          0 2021-11-16 16:52 /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src
[root@n138 ~]# su - tester -c "echo 'testfile hdfs' > /tmp/a_hdfs.txt"
[root@n138 ~]# su - tester -c "echo 'testfile hdfs 2' > /tmp/b_hdfs.txt"
[root@n138 ~]# ls -ltrah /tmp/*_hdfs.txt
-rw-rw-r-- 1 tester tester 14 Nov 16 17:00 /tmp/a_hdfs.txt
-rw-rw-r-- 1 tester tester 16 Nov 16 17:00 /tmp/b_hdfs.txt
[root@n138 ~]# su - tester -c 'hadoop fs -copyFromLocal /tmp/*_hdfs.txt hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]#
----
.. Überprüfen Sie die Berechtigungen im HDFS-Ordner.
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -ls hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
Found 2 items
-rw-r--r--   3 tester supergroup         14 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/a_hdfs.txt
-rw-r--r--   3 tester supergroup         16 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/b_hdfs.txt
----
.. Erstellen Sie einen Ordner in NFS und überprüfen Sie die Berechtigungen.
+
[listing]
----
[root@n138 ~]# su - tester -c 'mkdir /xcpsrc_vol/mohankarthiknfs_dest'
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
[root@n138 ~]# su - tester -c 'ls -d /xcpsrc_vol/mohankarthiknfs_dest'
/xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxrwxr-x 2 tester tester 4096 Nov 16 14:32 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----
.. Kopieren Sie die Dateien mit XCP von HDFS nach NFS und überprüfen Sie die Berechtigungen.
+
[listing]
----
[root@n138 ~]# su - tester -c '/usr/src/hdfs_nightly/xcp/linux/xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest'
XCP Nightly_dev; (c) 2021 NetApp, Inc.; Licensed to Karthikeyan Nagalingam [NetApp Inc] until Wed Feb  9 13:38:12 2022

xcp: WARNING: No index name has been specified, creating one with name: autoname_copy_2021-11-16_17.04.03.652673

Xcp command : xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest
Stats       : 3 scanned, 2 copied, 3 indexed
Speed       : 3.44 KiB in (650/s), 80.2 KiB out (14.8 KiB/s)
Total Time  : 5s.
STATUS      : PASSED
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
-rw-r--r-- 1 tester supergroup 14 Nov 16 17:01 a_hdfs.txt
-rw-r--r-- 1 tester supergroup 16 Nov 16 17:01 b_hdfs.txt
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxr-xr-x 2 tester supergroup 4096 Nov 16 17:01 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----



